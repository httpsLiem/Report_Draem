{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9490426,"sourceType":"datasetVersion","datasetId":5774015}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-08T07:15:28.835111Z","iopub.execute_input":"2024-10-08T07:15:28.835772Z","iopub.status.idle":"2024-10-08T07:15:29.871539Z","shell.execute_reply.started":"2024-10-08T07:15:28.835730Z","shell.execute_reply":"2024-10-08T07:15:29.870393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git clone https://github.com/LiemPham2011/DRAEM","metadata":{"execution":{"iopub.status.busy":"2024-10-09T15:43:43.388130Z","iopub.execute_input":"2024-10-09T15:43:43.388465Z","iopub.status.idle":"2024-10-09T15:43:44.813641Z","shell.execute_reply.started":"2024-10-09T15:43:43.388421Z","shell.execute_reply":"2024-10-09T15:43:44.812688Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Cloning into 'DRAEM'...\nremote: Enumerating objects: 6, done.\u001b[K\nremote: Counting objects: 100% (6/6), done.\u001b[K\nremote: Compressing objects: 100% (4/4), done.\u001b[K\nremote: Total 6 (delta 1), reused 6 (delta 1), pack-reused 0 (from 0)\u001b[K\nReceiving objects: 100% (6/6), done.\nResolving deltas: 100% (1/1), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install -r /kaggle/working/DRAEM/requirements.txt","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-10-09T15:43:53.119453Z","iopub.execute_input":"2024-10-09T15:43:53.119876Z","iopub.status.idle":"2024-10-09T15:44:29.424876Z","shell.execute_reply.started":"2024-10-09T15:43:53.119834Z","shell.execute_reply":"2024-10-09T15:44:29.423752Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting git+https://github.com/mlfoundations/open_clip.git (from -r /kaggle/working/DRAEM/requirements.txt (line 5))\n  Cloning https://github.com/mlfoundations/open_clip.git to /tmp/pip-req-build-f0n025c3\n  Running command git clone --filter=blob:none --quiet https://github.com/mlfoundations/open_clip.git /tmp/pip-req-build-f0n025c3\n  Resolved https://github.com/mlfoundations/open_clip.git to commit fc5a37b72d705f760ebbc7915b84729816ed471f\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hCollecting anomalib (from -r /kaggle/working/DRAEM/requirements.txt (line 1))\n  Downloading anomalib-1.1.1-py3-none-any.whl.metadata (27 kB)\nCollecting lightning (from -r /kaggle/working/DRAEM/requirements.txt (line 2))\n  Downloading lightning-2.4.0-py3-none-any.whl.metadata (38 kB)\nCollecting einops (from -r /kaggle/working/DRAEM/requirements.txt (line 3))\n  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\nCollecting FrEIA (from -r /kaggle/working/DRAEM/requirements.txt (line 4))\n  Downloading FrEIA-0.2.tar.gz (34 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting omegaconf>=2.1.1 (from anomalib->-r /kaggle/working/DRAEM/requirements.txt (line 1))\n  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\nRequirement already satisfied: rich>=13.5.2 in /opt/conda/lib/python3.10/site-packages (from anomalib->-r /kaggle/working/DRAEM/requirements.txt (line 1)) (13.7.1)\nCollecting jsonargparse>=4.27.7 (from jsonargparse[signatures]>=4.27.7->anomalib->-r /kaggle/working/DRAEM/requirements.txt (line 1))\n  Downloading jsonargparse-4.33.2-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: docstring-parser in /opt/conda/lib/python3.10/site-packages (from anomalib->-r /kaggle/working/DRAEM/requirements.txt (line 1)) (0.16)\nCollecting rich-argparse (from anomalib->-r /kaggle/working/DRAEM/requirements.txt (line 1))\n  Downloading rich_argparse-1.5.2-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: PyYAML<8.0,>=5.4 in /opt/conda/lib/python3.10/site-packages (from lightning->-r /kaggle/working/DRAEM/requirements.txt (line 2)) (6.0.2)\nRequirement already satisfied: fsspec<2026.0,>=2022.5.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning->-r /kaggle/working/DRAEM/requirements.txt (line 2)) (2024.6.1)\nRequirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from lightning->-r /kaggle/working/DRAEM/requirements.txt (line 2)) (0.11.6)\nRequirement already satisfied: packaging<25.0,>=20.0 in /opt/conda/lib/python3.10/site-packages (from lightning->-r /kaggle/working/DRAEM/requirements.txt (line 2)) (21.3)\nRequirement already satisfied: torch<4.0,>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from lightning->-r /kaggle/working/DRAEM/requirements.txt (line 2)) (2.4.0)\nRequirement already satisfied: torchmetrics<3.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from lightning->-r /kaggle/working/DRAEM/requirements.txt (line 2)) (1.4.1)\nRequirement already satisfied: tqdm<6.0,>=4.57.0 in /opt/conda/lib/python3.10/site-packages (from lightning->-r /kaggle/working/DRAEM/requirements.txt (line 2)) (4.66.4)\nRequirement already satisfied: typing-extensions<6.0,>=4.4.0 in /opt/conda/lib/python3.10/site-packages (from lightning->-r /kaggle/working/DRAEM/requirements.txt (line 2)) (4.12.2)\nRequirement already satisfied: pytorch-lightning in /opt/conda/lib/python3.10/site-packages (from lightning->-r /kaggle/working/DRAEM/requirements.txt (line 2)) (2.4.0)\nRequirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.10/site-packages (from FrEIA->-r /kaggle/working/DRAEM/requirements.txt (line 4)) (1.26.4)\nRequirement already satisfied: scipy>=1.5 in /opt/conda/lib/python3.10/site-packages (from FrEIA->-r /kaggle/working/DRAEM/requirements.txt (line 4)) (1.14.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from open_clip_torch==2.26.1->-r /kaggle/working/DRAEM/requirements.txt (line 5)) (0.19.0)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from open_clip_torch==2.26.1->-r /kaggle/working/DRAEM/requirements.txt (line 5)) (2024.5.15)\nCollecting ftfy (from open_clip_torch==2.26.1->-r /kaggle/working/DRAEM/requirements.txt (line 5))\n  Downloading ftfy-6.2.3-py3-none-any.whl.metadata (7.8 kB)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from open_clip_torch==2.26.1->-r /kaggle/working/DRAEM/requirements.txt (line 5)) (0.24.6)\nRequirement already satisfied: timm in /opt/conda/lib/python3.10/site-packages (from open_clip_torch==2.26.1->-r /kaggle/working/DRAEM/requirements.txt (line 5)) (1.0.8)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning->-r /kaggle/working/DRAEM/requirements.txt (line 2)) (3.9.5)\nCollecting typeshed-client>=2.1.0 (from jsonargparse[signatures]>=4.27.7->anomalib->-r /kaggle/working/DRAEM/requirements.txt (line 1))\n  Downloading typeshed_client-2.7.0-py3-none-any.whl.metadata (7.9 kB)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from lightning-utilities<2.0,>=0.10.0->lightning->-r /kaggle/working/DRAEM/requirements.txt (line 2)) (70.0.0)\nCollecting antlr4-python3-runtime==4.9.* (from omegaconf>=2.1.1->anomalib->-r /kaggle/working/DRAEM/requirements.txt (line 1))\n  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging<25.0,>=20.0->lightning->-r /kaggle/working/DRAEM/requirements.txt (line 2)) (3.1.2)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=13.5.2->anomalib->-r /kaggle/working/DRAEM/requirements.txt (line 1)) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=13.5.2->anomalib->-r /kaggle/working/DRAEM/requirements.txt (line 1)) (2.18.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=2.1.0->lightning->-r /kaggle/working/DRAEM/requirements.txt (line 2)) (3.15.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=2.1.0->lightning->-r /kaggle/working/DRAEM/requirements.txt (line 2)) (1.13.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=2.1.0->lightning->-r /kaggle/working/DRAEM/requirements.txt (line 2)) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=2.1.0->lightning->-r /kaggle/working/DRAEM/requirements.txt (line 2)) (3.1.4)\nRequirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /opt/conda/lib/python3.10/site-packages (from ftfy->open_clip_torch==2.26.1->-r /kaggle/working/DRAEM/requirements.txt (line 5)) (0.2.13)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->open_clip_torch==2.26.1->-r /kaggle/working/DRAEM/requirements.txt (line 5)) (2.32.3)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm->open_clip_torch==2.26.1->-r /kaggle/working/DRAEM/requirements.txt (line 5)) (0.4.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->open_clip_torch==2.26.1->-r /kaggle/working/DRAEM/requirements.txt (line 5)) (9.5.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning->-r /kaggle/working/DRAEM/requirements.txt (line 2)) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning->-r /kaggle/working/DRAEM/requirements.txt (line 2)) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning->-r /kaggle/working/DRAEM/requirements.txt (line 2)) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning->-r /kaggle/working/DRAEM/requirements.txt (line 2)) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning->-r /kaggle/working/DRAEM/requirements.txt (line 2)) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning->-r /kaggle/working/DRAEM/requirements.txt (line 2)) (4.0.3)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=13.5.2->anomalib->-r /kaggle/working/DRAEM/requirements.txt (line 1)) (0.1.2)\nRequirement already satisfied: importlib-resources>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from typeshed-client>=2.1.0->jsonargparse[signatures]>=4.27.7->anomalib->-r /kaggle/working/DRAEM/requirements.txt (line 1)) (6.4.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch<4.0,>=2.1.0->lightning->-r /kaggle/working/DRAEM/requirements.txt (line 2)) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->open_clip_torch==2.26.1->-r /kaggle/working/DRAEM/requirements.txt (line 5)) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->open_clip_torch==2.26.1->-r /kaggle/working/DRAEM/requirements.txt (line 5)) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->open_clip_torch==2.26.1->-r /kaggle/working/DRAEM/requirements.txt (line 5)) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->open_clip_torch==2.26.1->-r /kaggle/working/DRAEM/requirements.txt (line 5)) (2024.7.4)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch<4.0,>=2.1.0->lightning->-r /kaggle/working/DRAEM/requirements.txt (line 2)) (1.3.0)\nDownloading anomalib-1.1.1-py3-none-any.whl (424 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m425.0/425.0 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading lightning-2.4.0-py3-none-any.whl (810 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m811.0/811.0 kB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading einops-0.8.0-py3-none-any.whl (43 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading jsonargparse-4.33.2-py3-none-any.whl (208 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.5/208.5 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading ftfy-6.2.3-py3-none-any.whl (43 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.0/43.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading rich_argparse-1.5.2-py3-none-any.whl (19 kB)\nDownloading typeshed_client-2.7.0-py3-none-any.whl (624 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m624.4/624.4 kB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: FrEIA, open_clip_torch, antlr4-python3-runtime\n  Building wheel for FrEIA (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for FrEIA: filename=FrEIA-0.2-py3-none-any.whl size=42758 sha256=958eaba9161cd35d5a944c3fee7708897e62752231fefb38e6a2c2db9a54b48c\n  Stored in directory: /root/.cache/pip/wheels/81/a8/e2/d532a76f72108ac4a340cbe3f86b4f591abfdbd75209a5badb\n  Building wheel for open_clip_torch (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for open_clip_torch: filename=open_clip_torch-2.26.1-py3-none-any.whl size=1505848 sha256=84283648e3a93f78bdf829d3cb08841fe5854ef86ce9aa17f2c3dfa2b61ffe94\n  Stored in directory: /tmp/pip-ephem-wheel-cache-b3nbtfg4/wheels/2c/7e/51/c9df485368875ebcc36099a02e2cb98922dec2cba6be26917f\n  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=d6ca667ce15bb278ea3f50f4ee2e3752eb9d97551cce30acec32083d469ae650\n  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\nSuccessfully built FrEIA open_clip_torch antlr4-python3-runtime\nInstalling collected packages: antlr4-python3-runtime, typeshed-client, omegaconf, jsonargparse, ftfy, einops, rich-argparse, FrEIA, anomalib, open_clip_torch, lightning\nSuccessfully installed FrEIA-0.2 anomalib-1.1.1 antlr4-python3-runtime-4.9.3 einops-0.8.0 ftfy-6.2.3 jsonargparse-4.33.2 lightning-2.4.0 omegaconf-2.3.0 open_clip_torch-2.26.1 rich-argparse-1.5.2 typeshed-client-2.7.0\n","output_type":"stream"}]},{"cell_type":"code","source":"# Import the datamodule\nfrom anomalib.data import Folder\n\n# Create the datamodule\ndatamodule = Folder(\n    name=\"BottleAndCan\",\n    root=\"/kaggle/input/bottleandcan/bottleAndcan\",\n    normal_dir=\"good\",\n    abnormal_dir=\"bad\",\n    task=\"classification\",\n    train_batch_size=8, eval_batch_size=8, num_workers=3,\n)\n\n# Setup the datamodule\ndatamodule.setup()","metadata":{"execution":{"iopub.status.busy":"2024-10-09T15:47:33.389620Z","iopub.execute_input":"2024-10-09T15:47:33.390500Z","iopub.status.idle":"2024-10-09T15:47:34.434376Z","shell.execute_reply.started":"2024-10-09T15:47:33.390457Z","shell.execute_reply":"2024-10-09T15:47:34.433397Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Import the required modules\nfrom anomalib.models import Draem\nfrom anomalib.engine import Engine\n\n\nmodel = Draem(enable_sspcab=False, sspcab_lambda=0.1, anomaly_source_path=None, beta=(0.1, 1.0))\nengine = Engine(task=\"classification\",max_epochs=10,accelerator=\"gpu\", devices=[0, 1])\n# Train the model\nengine.fit(datamodule=datamodule, model=model)","metadata":{"execution":{"iopub.status.busy":"2024-10-09T15:49:43.348907Z","iopub.execute_input":"2024-10-09T15:49:43.349568Z","iopub.status.idle":"2024-10-09T16:21:04.117739Z","shell.execute_reply.started":"2024-10-09T15:49:43.349526Z","shell.execute_reply":"2024-10-09T16:21:04.116656Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"INFO: Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.\nINFO: GPU available: True (cuda), used: True\nINFO: TPU available: False, using: 0 TPU cores\nINFO: HPU available: False, using: 0 HPUs\nINFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"┏━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName                 \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType                    \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n┡━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ model                 │ DraemModel               │ 97.4 M │ train │\n│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ loss                  │ DraemLoss                │      0 │ train │\n│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _transform            │ Compose                  │      0 │ train │\n│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ normalization_metrics │ MetricCollection         │      0 │ train │\n│\u001b[2m \u001b[0m\u001b[2m4\u001b[0m\u001b[2m \u001b[0m│ image_threshold       │ F1AdaptiveThreshold      │      0 │ train │\n│\u001b[2m \u001b[0m\u001b[2m5\u001b[0m\u001b[2m \u001b[0m│ pixel_threshold       │ F1AdaptiveThreshold      │      0 │ train │\n│\u001b[2m \u001b[0m\u001b[2m6\u001b[0m\u001b[2m \u001b[0m│ image_metrics         │ AnomalibMetricCollection │      0 │ train │\n│\u001b[2m \u001b[0m\u001b[2m7\u001b[0m\u001b[2m \u001b[0m│ pixel_metrics         │ AnomalibMetricCollection │      0 │ train │\n└───┴───────────────────────┴──────────────────────────┴────────┴───────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name                  </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                     </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n┡━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ model                 │ DraemModel               │ 97.4 M │ train │\n│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ loss                  │ DraemLoss                │      0 │ train │\n│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _transform            │ Compose                  │      0 │ train │\n│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ normalization_metrics │ MetricCollection         │      0 │ train │\n│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>│ image_threshold       │ F1AdaptiveThreshold      │      0 │ train │\n│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5 </span>│ pixel_threshold       │ F1AdaptiveThreshold      │      0 │ train │\n│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 6 </span>│ image_metrics         │ AnomalibMetricCollection │      0 │ train │\n│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 7 </span>│ pixel_metrics         │ AnomalibMetricCollection │      0 │ train │\n└───┴───────────────────────┴──────────────────────────┴────────┴───────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1mTrainable params\u001b[0m: 97.4 M                                                                                           \n\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n\u001b[1mTotal params\u001b[0m: 97.4 M                                                                                               \n\u001b[1mTotal estimated model params size (MB)\u001b[0m: 389                                                                        \n\u001b[1mModules in train mode\u001b[0m: 229                                                                                         \n\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 97.4 M                                                                                           \n<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n<span style=\"font-weight: bold\">Total params</span>: 97.4 M                                                                                               \n<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 389                                                                        \n<span style=\"font-weight: bold\">Modules in train mode</span>: 229                                                                                         \n<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Output()","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2cfc7e58284c46c59ad8a268edc5eac7"}},"metadata":{}},{"name":"stderr","text":"INFO: `Trainer.fit` stopped: `max_epochs=10` reached.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n</pre>\n"},"metadata":{}}]}]}